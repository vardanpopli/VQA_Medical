{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7188971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8da97e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "medidata = pd.read_excel(\"C:\\\\Users\\\\varda\\\\Documents\\\\mltask2\\\\VQA_RAD Dataset Public.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bafded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling the data \n",
    "\n",
    "sampledata = medidata[(medidata[\"ANSWER\"] == \"Yes\") | (medidata[\"ANSWER\"] == \"No\") | (medidata[\"ANSWER\"] == \"yes\") | (medidata[\"ANSWER\"] == \"no\") ]\n",
    "sampledata.reset_index(inplace = True, drop = True)\n",
    "#sampledata\n",
    "\n",
    "questions = sampledata.iloc[:,7].values\n",
    "answers = sampledata.iloc[:,12].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9c24fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79202940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating labels\n",
    "labels = np.zeros((len(sampledata),))\n",
    "for i in range(len(sampledata)):\n",
    "    if (sampledata[\"ANSWER\"][i] == \"Yes\") | (sampledata[\"ANSWER\"][i] == \"yes\"):\n",
    "        labels[i] = 1\n",
    "    elif (sampledata[\"ANSWER\"][i] == \"No\") | (sampledata[\"ANSWER\"][i] == \"no\"):\n",
    "        labels[i] = 0\n",
    "    else:\n",
    "        labels[i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0044c53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/varda/Documents/mltask2/VAQ image folder/synpic54610.jpg',\n",
       " 'C:/Users/varda/Documents/mltask2/VAQ image folder/synpic29265.jpg',\n",
       " 'C:/Users/varda/Documents/mltask2/VAQ image folder/synpic29265.jpg',\n",
       " 'C:/Users/varda/Documents/mltask2/VAQ image folder/synpic29265.jpg',\n",
       " 'C:/Users/varda/Documents/mltask2/VAQ image folder/synpic28602.jpg',\n",
       " 'C:/Users/varda/Documents/mltask2/VAQ image folder/synpic28602.jpg',\n",
       " 'C:/Users/varda/Documents/mltask2/VAQ image folder/synpic28602.jpg',\n",
       " 'C:/Users/varda/Documents/mltask2/VAQ image folder/synpic42202.jpg',\n",
       " 'C:/Users/varda/Documents/mltask2/VAQ image folder/synpic29265.jpg',\n",
       " 'C:/Users/varda/Documents/mltask2/VAQ image folder/synpic54610.jpg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# image address\n",
    "IMGDIR = \"C:/Users/varda/Documents/mltask2/VAQ image folder/\"\n",
    "\n",
    "addresses = []\n",
    "for i in range(len(sampledata)):\n",
    "    addresses.append(IMGDIR + sampledata[\"IMAGEID\"][i][39:])\n",
    "addresses[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0195383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image pre-processing\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "target_size = (224, 224)\n",
    "\n",
    "# Define a function to load and preprocess image from a file path\n",
    "def preprocess_image(file_path):\n",
    "    # Read the image from the file\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_image(image, channels=3) \n",
    "\n",
    "    # Resize the image\n",
    "    image = tf.image.resize(image, target_size)\n",
    "    \n",
    "    # Normalize pixel values to the range [0, 1]\n",
    "    image = image / 255.0\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Load and preprocess all images from the list of file paths\n",
    "images = [preprocess_image(file_path) for file_path in addresses]\n",
    "\n",
    "# Convert the list of preprocessed images to a tensorflow tensor\n",
    "normalized_images = tf.convert_to_tensor(images, dtype=tf.float32)\n",
    "\n",
    "# Now, normalized_images contains the images resized to 224x224 pixels and with pixel values normalized to [0, 1].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "99432b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augmentation functions\n",
    "def augment_image(image):\n",
    "    # Randomly apply rotation\n",
    "    k = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n",
    "    \n",
    "    image = tf.image.rot90(image, k=k)\n",
    "    \n",
    "    # Randomly flip the image horizontally\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    \n",
    "    # Randomly adjust brightness (factor between 0.5 and 1.5)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.5)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Apply data augmentation to each image\n",
    "augmented_images = [augment_image(image) for image in images]\n",
    "\n",
    "# Convert the list of augmented images to a tensorflow tensor\n",
    "augmented_images_float = tf.convert_to_tensor(augmented_images, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f83a9fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1192"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(augmented_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e0f6dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Tokenize the questions and answers\n",
    "tokenized_data = []\n",
    "\n",
    "for question, answer in zip(questions, answers):\n",
    "    question_doc = nlp(question)\n",
    "    answer_doc = nlp(answer)\n",
    "    tokenized_item = {\n",
    "        \"question_tokens\": [token.text for token in question_doc],\n",
    "        \"answer_tokens\": [token.text for token in answer_doc],\n",
    "    }\n",
    "    tokenized_data.append(tokenized_item)\n",
    "    \n",
    "# Now, tokenized_data contains tokenized questions and answers for each item.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3266c7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saperately tokenizing the questions and answers ans storing in the following list\n",
    "tokenized_questions = []\n",
    "tokenized_answers = []\n",
    "\n",
    "for question, answer in zip(questions, answers):\n",
    "    question_doc = nlp(question)\n",
    "    answer_doc = nlp(answer)\n",
    "    tokenized_questions.append([token.text for token in question_doc])\n",
    "    tokenized_answers.append([token.text for token in answer_doc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2d32a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddd0ca33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "Is\n",
      "the\n",
      "No\n",
      "there\n",
      "Yes\n",
      "this\n",
      "yes\n",
      "in\n",
      "a\n",
      "of\n",
      "Are\n",
      "image\n",
      "no\n",
      "present\n",
      "normal\n",
      "mass\n",
      "Does\n",
      "patient\n",
      "evidence\n",
      "an\n",
      "contrast\n",
      "air\n",
      "any\n",
      "heart\n",
      "left\n",
      "is\n",
      "right\n",
      "Can\n",
      "enlarged\n",
      "lesion\n",
      "on\n",
      "-\n",
      "liver\n",
      "lung\n",
      "you\n",
      "brain\n",
      "abnormal\n",
      "bowel\n",
      "to\n",
      "pneumothorax\n",
      "size\n",
      "kidneys\n",
      "Do\n",
      "midline\n",
      "fracture\n",
      "effusion\n",
      "be\n",
      "pleural\n",
      "visualized\n",
      "ventricles\n",
      "plane\n",
      "CT\n",
      "lungs\n",
      "see\n",
      "and\n",
      "diaphragm\n",
      "fluid\n",
      "shift\n",
      "with\n",
      "appear\n",
      "skull\n",
      "axial\n",
      "fractured\n",
      "section\n",
      "have\n",
      "aorta\n",
      "free\n",
      "small\n",
      "trachea\n",
      "fat\n",
      "Was\n",
      "taken\n",
      "'s\n",
      "show\n",
      "chest\n",
      "visible\n",
      "than\n",
      "enhancing\n",
      "cardiomegaly\n",
      "aortic\n",
      "fractures\n",
      "under\n",
      "film\n",
      "cardiac\n",
      "ribs\n",
      "matter\n",
      "MRI\n",
      "white\n",
      "kidney\n",
      "structures\n",
      "both\n",
      "findings\n",
      "abdominal\n",
      "seen\n",
      "silhouette\n",
      "costophrenic\n",
      "IV\n",
      "stranding\n",
      "located\n",
      "lobe\n",
      "gallbladder\n",
      "well\n",
      "used\n",
      "arteries\n",
      "lesions\n",
      "pulmonary\n",
      "temporal\n",
      "PA\n",
      "hemorrhage\n",
      "hemidiaphragm\n",
      "view\n",
      "colon\n",
      "abnormalities\n",
      "wall\n",
      "vertebral\n",
      "grey\n",
      "edema\n",
      "enlargement\n",
      "rib\n",
      "pneumoperitoneum\n",
      "deviation\n",
      "dilated\n",
      "ray\n",
      "x\n",
      "at\n",
      "effect\n",
      "scan\n",
      "side\n",
      "appendix\n",
      "ring\n",
      "cerebellum\n",
      "enhancement\n",
      "or\n",
      "levels\n",
      "large\n",
      "lateral\n",
      "enhanced\n",
      "lymphadenopathy\n",
      "process\n",
      "contour\n",
      "more\n",
      "tracheal\n",
      "angle\n",
      "cyst\n",
      "near\n",
      "tissue\n",
      "cerebral\n",
      "markings\n",
      "increased\n",
      "given\n",
      "blunting\n",
      "level\n",
      "from\n",
      "\t\n",
      "Did\n",
      "by\n",
      "was\n",
      "system\n",
      "fields\n",
      "renal\n",
      "one\n",
      "hyper\n",
      "parenchyma\n",
      "calcifications\n",
      "stomach\n",
      "field\n",
      "appreciate\n",
      "thickening\n",
      "pancreas\n",
      "trunk\n",
      "these\n",
      "celiac\n",
      "pathology\n",
      "above\n",
      "mediastinum\n",
      "anything\n",
      "shown\n",
      "calcified\n",
      "thickened\n",
      "hilar\n",
      "pathologic\n",
      "xray\n",
      "calcification\n",
      "abdomen\n",
      "homogenous\n",
      "abnormality\n",
      "it\n",
      "/\n",
      "pancreatic\n",
      "cavity\n",
      "descending\n",
      "sides\n",
      "other\n",
      "gray\n",
      "herniation\n",
      "hilum\n",
      "sulci\n",
      "subcutaneous\n",
      "border\n",
      "modality\n",
      "cystic\n",
      "walls\n",
      "are\n",
      "blood\n",
      "clearly\n",
      "atrophied\n",
      "inflammation\n",
      "oral\n",
      "surrounding\n",
      "within\n",
      "look\n",
      "perforated\n",
      "opacities\n",
      "angles\n",
      "abnormally\n",
      "coronal\n",
      "aneurysm\n",
      "bone\n",
      "vascular\n",
      "patent\n",
      "thorax\n",
      "Has\n",
      "AP\n",
      "borders\n",
      "pelvis\n",
      "half\n",
      "hematoma\n",
      "atrophy\n",
      "hyperinflated\n",
      "brainstem\n",
      "defined\n",
      "consolidation\n",
      "masses\n",
      "bleeding\n",
      "placed\n",
      "tube\n",
      "supine\n",
      "represent\n",
      ">\n",
      "artery\n",
      "mesenteric\n",
      "anterior\n",
      "display\n",
      "head\n",
      "subdural\n",
      "GI\n",
      "widened\n",
      "vasculature\n",
      "peritoneal\n",
      "width\n",
      "deviated\n",
      "transverse\n",
      "bleed\n",
      "for\n",
      "attenuated\n",
      "here\n",
      "distended\n",
      "radiograph\n",
      ")\n",
      "affected\n",
      "position\n",
      "multiple\n",
      "ascites\n",
      "around\n",
      "CXR\n",
      "spleen\n",
      "depicted\n",
      "occipital\n",
      "wrong\n",
      "soft\n",
      "appreciated\n",
      "organs\n",
      "blunted\n",
      "diagnosis\n",
      "injury\n",
      "diagnose\n",
      "infarction\n",
      "possible\n",
      "sided\n",
      "ventricle\n",
      "filled\n",
      "vertebrae\n",
      "hydronephrosis\n",
      "superior\n",
      "nodules\n",
      "limits\n",
      "same\n",
      "lying\n",
      "vein\n",
      "between\n",
      "apex\n",
      "contain\n",
      "diameter\n",
      "interstitial\n",
      "weighted\n",
      "good\n",
      "study\n",
      "circumscribed\n",
      "open\n",
      "dilation\n",
      "inferior\n",
      "junction\n",
      "material\n",
      "mid\n",
      "bilateral\n",
      "nodes\n",
      "lymph\n",
      "cavitary\n",
      "shifted\n",
      "heterogenous\n",
      "structure\n",
      "common\n",
      "gallstones\n",
      "flattened\n",
      "loculated\n",
      "high\n",
      "able\n",
      "swelling\n",
      "saggital\n",
      "mediastinal\n",
      "posterior\n",
      "presence\n",
      "receive\n",
      "does\n",
      "shape\n",
      "esophagus\n",
      "all\n",
      "Any\n",
      "gastric\n",
      "obstruction\n",
      "clavicles\n",
      "midbrain\n",
      "densities\n",
      "cortex\n",
      "intubated\n",
      "acute\n",
      "blurring\n",
      "broken\n",
      "subdiaphragmatic\n",
      "hyperinflation\n",
      "peritoneum\n",
      "besides\n",
      "noncontrast\n",
      "intussusception\n",
      "cortical\n",
      "body\n",
      "differentiation\n",
      "upper\n",
      "arch\n",
      "symmetrical\n",
      "secondary\n",
      "tension\n",
      "if\n",
      "edematous\n",
      "lobes\n",
      "significant\n",
      "5\n",
      "sinuses\n",
      "middle\n",
      "collection\n",
      "compressed\n",
      "involvement\n",
      "appearing\n",
      "properly\n",
      "sharp\n",
      "medical\n",
      "perforation\n",
      "bones\n",
      "leakage\n",
      "shifting\n",
      "hyperintensities\n",
      "healthy\n",
      "intestines\n",
      "infiltrating\n",
      "obscured\n",
      "therapy\n",
      "swollen\n",
      "medulla\n",
      "gyri\n",
      "hypodense\n",
      "lower\n",
      "wider\n",
      "nodule\n",
      "(\n",
      "signal\n",
      "viewed\n",
      "basilar\n",
      "identified\n",
      "alveoli\n",
      "differentiated\n",
      "consolidations\n",
      "appropriately\n",
      "sagittal\n",
      "positioned\n",
      "two\n",
      "larger\n",
      "T1\n",
      "enhance\n",
      "restricted\n",
      "symmetric\n",
      "epidural\n",
      "R\n",
      "diffusion\n",
      "vena\n",
      "muscles\n",
      "horns\n",
      "layering\n",
      "dependent\n",
      "top\n",
      "uniform\n",
      "finding\n",
      "shaped\n",
      "cause\n",
      "decreased\n",
      "without\n",
      "veins\n",
      "ductal\n",
      "interior\n",
      "intrahepatic\n",
      "infiltrates\n",
      "patchy\n",
      "bowels\n",
      "showing\n",
      "horn\n",
      "bases\n",
      "airway\n",
      "compressing\n",
      "across\n",
      "adenopathy\n",
      "conal\n",
      "flat\n",
      "8\n",
      "fascia\n",
      "signs\n",
      "least\n",
      "subarachnoid\n",
      "sign\n",
      "either\n",
      "hemidiaphragms\n",
      "identify\n",
      "inflamed\n",
      "wedge\n",
      "cava\n",
      "inspiratory\n",
      "as\n",
      "hepatic\n",
      "failure\n",
      "hylar\n",
      "anoxic\n",
      "4th\n",
      "use\n",
      "appendicitis\n",
      "intensity\n",
      "humerus\n",
      "hypodensity\n",
      "suspect\n",
      "damage\n",
      "physical\n",
      "less\n",
      "pads\n",
      "Would\n",
      "IS\n",
      "neoplastic\n",
      "made\n",
      "pericardial\n",
      "apical\n",
      "evaluate\n",
      "branches\n",
      "highlighted\n",
      "enough\n",
      "sufficient\n",
      "adequate\n",
      "dilatation\n",
      "effort\n",
      "underexposed\n",
      "involved\n",
      "gall\n",
      "nucleus\n",
      "caudate\n",
      "CSF\n",
      "effusions\n",
      "bladder\n",
      "portal\n",
      "intraperitoneal\n",
      "involve\n",
      "arterial\n",
      "diffuse\n",
      "intraparenchymal\n",
      "clavicle\n",
      "GB\n",
      "airspace\n",
      "iliac\n",
      "cytotoxic\n",
      "selected\n",
      "regions\n",
      "viscus\n",
      "colonic\n",
      "costovertebral\n",
      "lumen\n",
      "cardiomyopathy\n",
      "ileac\n",
      "infarcted\n",
      "penetration\n",
      "tilting\n",
      "include\n",
      "cardia\n",
      "pictured\n",
      "smooth\n",
      "12\n",
      "phase\n",
      "narrowing\n",
      "slight\n",
      "venous\n",
      "vertebro\n",
      "causing\n",
      "network\n",
      "junctions\n",
      "T2\n",
      "MCA\n",
      "definitive\n",
      "stool\n",
      "congestion\n",
      "attenuating\n",
      "feces\n",
      "engorged\n",
      "hypo-\n",
      "hyperattenuations\n",
      "format\n",
      "ectopic\n",
      "metastatic\n",
      "noted\n",
      "along\n",
      "tortuosity\n",
      "pushing\n",
      "visceral\n",
      "cm\n",
      "1\n",
      "indicative\n",
      "aging\n",
      "observed\n",
      "degenerative\n",
      "changes\n",
      "pleura\n",
      "outline\n",
      "difficult\n",
      "into\n",
      "stretched\n",
      "hernia\n",
      "Have\n",
      "crossed\n",
      "midlight\n",
      "equivalent\n",
      "delineate\n",
      "associated\n",
      "aeration\n",
      "motion\n",
      "cut\n",
      "intense\n",
      "sigmoid\n",
      "duct\n",
      "biliary\n",
      "perinephric\n",
      "ET\n",
      "evident\n",
      "outside\n",
      "inflammed\n",
      "complex\n",
      "septations\n",
      "cirrhotic\n",
      "pericholecystic\n",
      "underneath\n",
      "margins\n",
      "hyperdense\n",
      "cerebellar\n",
      "infarcts\n",
      "encephalon\n",
      "greater\n",
      "smaller\n",
      "picture\n",
      "Were\n",
      "intestinalis\n",
      "pneumo\n",
      "aneurysmal\n",
      "corpus\n",
      "ectatic\n",
      "orbits\n",
      "indicate\n",
      "do\n",
      "What\n",
      "callosum\n",
      "gas\n",
      "identifiable\n",
      "blocked\n",
      "altered\n",
      "cortexes\n",
      "knob\n",
      "wide\n",
      "get\n",
      "implant\n",
      "metal\n",
      "joints\n",
      "skeletal\n",
      "tissues\n",
      "assess\n",
      "rays\n",
      "encompassed\n",
      "ventricular\n",
      "mismatch\n",
      "Q\n",
      "pneuomothorax\n",
      "clavicular\n",
      "lacerated\n",
      "Besides\n",
      "not\n",
      "consistency\n",
      "gyral\n",
      "trapped\n",
      "enhancements\n",
      ",\n",
      "focal\n",
      "unaltered\n",
      "localized\n",
      "physiology\n",
      "irregular\n",
      "accumulation\n",
      "bulging\n",
      "varied\n",
      "50\n",
      "%\n",
      "intestinal\n",
      "EKG\n",
      "displaced\n",
      "easily\n",
      "looking\n",
      "tumor\n",
      "collapsed\n",
      "X\n",
      "kind\n",
      "special\n",
      "tract\n",
      "angle(s\n",
      "plain\n",
      "Notice\n",
      "suspected\n",
      "test\n",
      "imaging\n",
      "lung(s\n",
      "obvious\n",
      "seem\n",
      "unified\n",
      "distension\n",
      "clear\n",
      "infiltrate\n",
      "difference\n",
      "assessed\n",
      "infectious\n",
      "etiology\n",
      "vertebra\n",
      "pseudocyst\n",
      "pseudocsyst\n",
      "Will\n",
      "alone\n",
      "managed\n",
      "can\n",
      "first\n",
      "KUB\n",
      "flattening\n",
      "central\n",
      "bile\n",
      "them\n",
      "big\n",
      "too\n",
      "L\n",
      "line\n",
      "airways\n",
      "Anything\n",
      "bronchial\n",
      "clot\n",
      "NG\n",
      "inspiration\n",
      "density\n",
      "leads\n",
      "ducts\n",
      "preserved\n",
      "mirror\n",
      "FLAIR\n",
      "backwards\n",
      "jejunum\n",
      "jejunal\n",
      "higher\n",
      "elevation\n",
      "protocol\n",
      "inappropriately\n",
      "circumferential\n",
      "rotated\n",
      "non\n",
      "most\n",
      "slice\n",
      "via\n",
      "throughout\n",
      "V\n",
      "cilia\n",
      "artifact\n",
      "applied\n",
      "solitary\n",
      "alteration\n",
      "ganglia\n",
      "basal\n",
      "structural\n",
      "choroid\n",
      "path\n",
      "exposed\n",
      "inappropriate\n",
      "opacity\n",
      "neck\n",
      "fifth\n",
      "5th\n",
      "duodenum\n",
      "fossae\n",
      "anatomy\n",
      "its\n",
      "height\n",
      "recognizable\n",
      "impression\n",
      "ureters\n",
      "r\n",
      "bladde\n",
      "down\n",
      "fluids\n",
      "sections\n",
      "cysts\n",
      "women\n",
      "pregnant\n",
      "safe\n",
      "highlight\n",
      "about\n",
      "shrunk\n",
      "supraclavicular\n",
      "that\n",
      "shadow\n",
      "lumbar\n",
      "been\n",
      "cholecystectomy\n",
      "pelvic\n",
      "ischemic\n",
      "gastrointestinal\n",
      "typical\n",
      "displayed\n",
      "herniated\n",
      "light\n",
      "hi\n",
      "h\n",
      "stomac\n",
      "n\n",
      "splee\n",
      "radioopaque\n",
      "removed\n",
      "2\n",
      "number\n",
      "extend\n",
      "periappendiceal\n",
      "lighter\n",
      "organ\n",
      "nodular\n",
      "exceed\n",
      "periphery\n",
      "thoracic\n",
      "like\n",
      "entire\n",
      "phlegmon\n",
      "cecum\n",
      "neighboring\n",
      "affect\n",
      "homogeneous\n",
      "likely\n",
      "perform\n",
      "AKI\n",
      "prominently\n",
      "Right\n",
      "expiration\n",
      "best\n",
      "normally\n",
      "consistent\n",
      "also\n",
      "using\n",
      "recommend\n",
      "always\n",
      "demonstrate\n",
      "mri\n",
      "Saggital\n",
      "pneumomediastinum\n",
      "contents\n",
      "nerve\n",
      "bleeds\n",
      "hemorrhagic\n",
      "oriented\n",
      "their\n",
      "growing\n",
      "encompassing\n",
      "confined\n",
      "only\n",
      "pericolic\n",
      "pericolonic\n",
      "Evidence\n",
      "patients\n",
      "taking\n",
      "prior\n",
      "ingest\n",
      "take\n",
      "symmetry\n",
      "'\n",
      "optic\n",
      "ruptured\n",
      "endotracheal\n",
      "originate\n",
      "visualize\n",
      "inflated\n",
      "confirmed\n",
      "detect\n",
      "verterbral\n",
      "primary\n",
      "problem\n",
      "obstructed\n",
      "adrenals\n",
      "glands\n",
      "adrenal\n",
      "anywhere\n",
      "evaluated\n",
      "sustain\n",
      "obstrution\n",
      "constitute\n",
      "we\n",
      "CV\n",
      "dissection\n",
      "suggestive\n",
      "hydrocephalus\n",
      "CNS\n",
      "cardiovascular\n",
      "parts\n",
      "depict\n",
      "describe\n",
      "Doe\n",
      "demonstrated\n",
      "fullness\n",
      "mediastium\n",
      "standing\n",
      "loculation\n",
      "fissure\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Combine all tokens from questions and answers\n",
    "all_tokens = [item[\"question_tokens\"] + item[\"answer_tokens\"] for item in tokenized_data]\n",
    "\n",
    "# Train a Word2Vec model\n",
    "model = Word2Vec(sentences=all_tokens, vector_size=100, window=5, sg=0, min_count=1, workers=4)\n",
    "\n",
    "model.save(\"cbow_Q_A_model.model\")\n",
    "model = Word2Vec.load(\"cbow_Q_A_model.model\")\n",
    "\n",
    "\n",
    "# word embeddings\n",
    "word_embeddings = {}\n",
    "\n",
    "for token in model.wv.index_to_key:\n",
    "    word_embeddings[token] = model.wv[token]\n",
    "\n",
    "# Now, word_embeddings contains Word2Vec embeddings for the tokens.\n",
    "\n",
    "for question_embeddings in word_embeddings:\n",
    "    print(question_embeddings)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca3bdb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating vocabulary\n",
    "unique_words = list(word_embeddings.keys())\n",
    "\n",
    "# Create a vocabulary dictionary where each word is mapped to a unique ID\n",
    "word_to_id = {word: index for index, word in enumerate(unique_words)}\n",
    "\n",
    "# Now, 'word_to_id' is vocabulary mappings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1366d596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41ce6f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# define a directory where we will save the images\n",
    "output_directory = \"C:/Users/varda/Documents/mltask2/VQA_augmented_images_folder/\"  # Replace with your desired output directory\n",
    "\n",
    "# creating the output directory \n",
    "tf.io.gfile.makedirs(output_directory)\n",
    "\n",
    "# loop through the augmented images and save them to the output directory\n",
    "for i, image in enumerate(augmented_images):\n",
    "    image_bytes = tf.image.encode_jpeg(tf.cast(image * 255, tf.uint8))\n",
    "    filename = f\"augmented_image_{i}.jpg\"  # You can adjust the naming scheme\n",
    "    file_path = tf.strings.join([output_directory, filename])\n",
    "    tf.io.write_file(file_path, image_bytes)\n",
    "    #print(f\"Saved {filename} to {output_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9386c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the image address to load the images for feature extraction\n",
    "\n",
    "image_paths =[]\n",
    "for i in range (0,1192):\n",
    "\n",
    "    image_address = output_directory + f\"augmented_image_{i}.jpg\"\n",
    "    image_paths.append(image_address)\n",
    "    #print(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb234323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/varda/Documents/mltask2/VQA_augmented_images_folder/augmented_image_1191.jpg\n"
     ]
    }
   ],
   "source": [
    "print(image_address)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4e1df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing image feature extraction\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# loading the pre-trained ResNet50 model \n",
    "resnet_model = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
    "\n",
    "resnet = hub.load(resnet_model)\n",
    "image_size = (224, 224)\n",
    "image_features = []\n",
    "\n",
    "\n",
    "for image_path in image_paths:\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_image(img, channels=3)  # Ensure RGB images\n",
    "    img = tf.image.resize(img, image_size)\n",
    "    img = img / 255.0  # Normalize pixel values\n",
    "    img = tf.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    features = resnet(img)\n",
    "    image_features.append(features)\n",
    "\n",
    "# concatenate the image features\n",
    "image_features = tf.concat(image_features, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911af477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef98263d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1192"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_features) #extra things for my information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9f4d501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "max_length = 0                 #extra things for my information\n",
    "for question in tokenized_questions:\n",
    "    length = len(question)\n",
    "    if length > max_length:\n",
    "        max_length = length\n",
    "print(max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67e961dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "849"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(word_to_id.items()))    #extra things for my information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3ad057f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "849"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = list(word_embeddings.keys())    #extra things for my information\n",
    "len(dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c98649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e786b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding the tokens, truncating the questions.\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# create a tokenizer to map words to IDs\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(tokenized_questions)\n",
    "\n",
    "# convert tokenized questions to sequences\n",
    "question_sequences = tokenizer.texts_to_sequences(tokenized_questions)\n",
    "\n",
    "max_sequence_length = 22\n",
    "\n",
    "padded_question_sequences = pad_sequences(question_sequences, maxlen=max_sequence_length, padding='post', truncating='post')\n",
    "\n",
    "# convert the padded sequences to tensors\n",
    "question_tokens = tf.constant(padded_question_sequences)\n",
    "\n",
    "# Now, question_input contains the padded and truncated question sequences as tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c7127bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model creation\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Concatenate, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "image_input = tf.keras.Input(shape=(2048,), name='image_input')\n",
    "\n",
    "question_input = tf.keras.Input(shape=(22,), name='question_input')\n",
    "\n",
    "question_embedding = layers.Embedding(input_dim=849, output_dim=849)(question_input)\n",
    "\n",
    "# Add one or more LSTM layers for processing the question text\n",
    "question_lstm = LSTM(units=256, return_sequences=False)(question_embedding)\n",
    "\n",
    "# Concatenate the image features and question LSTM output\n",
    "concatenated_features = layers.concatenate([image_input, question_lstm])\n",
    "\n",
    "# Add one or more dense layers for joint understanding\n",
    "joint_dense = layers.Dense(512, activation='relu')(concatenated_features)\n",
    "\n",
    "output = layers.Dense(1, activation='softmax')(joint_dense)\n",
    "\n",
    "# Create the VQA model\n",
    "vqa_model = tf.keras.Model(inputs=[image_input, question_input], outputs=output)\n",
    "\n",
    "# Compile the model with optimizer and loss function\n",
    "vqa_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2ac057b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting question and labesl for training\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "q = padded_question_sequences # Features: questions and answers\n",
    "y = labels  # Labels: anwers\n",
    "\n",
    "train_size = 0.7 \n",
    "validation_size = 0.15  \n",
    "test_size = 0.15  \n",
    "\n",
    "q_train, q_temp, y_train, y_temp = train_test_split(q, y, test_size=(1 - train_size), random_state=42)\n",
    "q_val, q_test, y_val, y_test = train_test_split(q_temp, y_temp, test_size=test_size / (1 - train_size), random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1f314df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting image features for training\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the desired split percentages\n",
    "train_percent = 0.7\n",
    "validation_percent = 0.15\n",
    "test_percent = 0.15\n",
    "\n",
    "num_samples = len(image_features)\n",
    "num_train = int(train_percent * num_samples)\n",
    "num_validation = 179\n",
    "\n",
    "X_train, X_temp = image_features[:num_train], image_features[num_train:]\n",
    "X_val, X_test = X_temp[:num_validation], X_temp[num_validation:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb0a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d67b86e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 [==============================] - 6s 130ms/step - loss: 0.0000e+00 - accuracy: 0.4868 - val_loss: 0.0000e+00 - val_accuracy: 0.4916\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 3s 118ms/step - loss: 0.0000e+00 - accuracy: 0.4868 - val_loss: 0.0000e+00 - val_accuracy: 0.4916\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 3s 117ms/step - loss: 0.0000e+00 - accuracy: 0.4868 - val_loss: 0.0000e+00 - val_accuracy: 0.4916\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 4s 134ms/step - loss: 0.0000e+00 - accuracy: 0.4868 - val_loss: 0.0000e+00 - val_accuracy: 0.4916\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 3s 119ms/step - loss: 0.0000e+00 - accuracy: 0.4868 - val_loss: 0.0000e+00 - val_accuracy: 0.4916\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 3s 129ms/step - loss: 0.0000e+00 - accuracy: 0.4868 - val_loss: 0.0000e+00 - val_accuracy: 0.4916\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 3s 115ms/step - loss: 0.0000e+00 - accuracy: 0.4868 - val_loss: 0.0000e+00 - val_accuracy: 0.4916\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 3s 126ms/step - loss: 0.0000e+00 - accuracy: 0.4868 - val_loss: 0.0000e+00 - val_accuracy: 0.4916\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 3s 117ms/step - loss: 0.0000e+00 - accuracy: 0.4868 - val_loss: 0.0000e+00 - val_accuracy: 0.4916\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 3s 129ms/step - loss: 0.0000e+00 - accuracy: 0.4868 - val_loss: 0.0000e+00 - val_accuracy: 0.4916\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0000e+00 - accuracy: 0.5140\n",
      "Test Loss: 0.0, Test Accuracy: 0.5139665007591248\n"
     ]
    }
   ],
   "source": [
    "# finding Accuracy\n",
    "num_epochs = 10  \n",
    "batch_size = 32  \n",
    "\n",
    "history = vqa_model.fit(\n",
    "    [X_train, q_train], y_train,  # Provide image features, questions, and answers\n",
    "    validation_data= ([X_val, q_val], y_val),    epochs= num_epochs,  batch_size= batch_size)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = vqa_model.evaluate([X_test, q_test], y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "\n",
    "# hence, accuracy is comming out to be 0.5139\n",
    "# now after fine tuning, by applying different model eg. BERT, GPT-2 we can find more btter accuracy(I have tried, but didn't run)\n",
    "# so did it from scrach\n",
    "# or we can do more augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "07f71d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "834.4"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = len(image_features)\n",
    "\n",
    "x*0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "30c349ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "834"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f02473bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "834"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d40a451a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "834"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4daf0f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1191.4285714285716"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "834/0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ba68da5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "834.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1112*0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "538ec4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6996644295302014"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "834/1192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "71fdf3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13993288590604025"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1112*0.15)/1192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d656ecac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
